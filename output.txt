Comparing embeddings with gensim embeddings using cosine similarity.

king       → cosine similarity = 0.010555779561400414
queen      → cosine similarity = 0.007837611250579357
man        → cosine similarity = -0.037494175136089325
woman      → cosine similarity = -0.021711383014917374
computer   → cosine similarity = 0.010824250988662243
science    → cosine similarity = 0.09402227401733398


Word analogy based on trained embeddings.

man:king :: woman:?
[('prince', np.float32(0.44625783)), ('kings', np.float32(0.42751917)), ('ruler', np.float32(0.42003956)), ('son', np.float32(0.40526396)), ('emperor', np.float32(0.4030922))]
paris:france :: italy:?
[('burgundian', np.float32(0.4710237)), ('lithuania', np.float32(0.47017932)), ('svg', np.float32(0.45574582)), ('moorish', np.float32(0.43278557)), ('belgium', np.float32(0.42852616))]
big:bigger :: small:?
[('weighing', np.float32(0.36227453)), ('inaccessible', np.float32(0.344976)), ('large', np.float32(0.34279728)), ('sizeable', np.float32(0.33498058)), ('refered', np.float32(0.33155978))]
good:better :: bad:?
[('proclus', np.float32(0.32231736)), ('darker', np.float32(0.31558138)), ('performances', np.float32(0.3111294)), ('multiplier', np.float32(0.30854952)), ('fuji', np.float32(0.30491662))]


Detecting bias in embeddings.

doctor      : -0.3238981287842498
nurse       : -0.23460782442169786
engineer    : 0.517427933248224
programmer  : -0.24719643818566622
teacher     : -0.20855594605854672
scientist   : -0.2111775828910653
artist      : -0.1905689033998214
lawyer      : -0.30355155697413005
